{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational Model Metric\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = categorical_crossentropy(y_pred, y_true)\n",
    "    return pow(2, cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especify model directory\n",
    "modelDir = 'logs_trained_models_server/model_epochs-155_batch-32_hidden-128_embed-264_v0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables\n",
    "word2index_inp = pk.load(open(os.path.join(modelDir,'word2index_inp.pk'), 'rb'))\n",
    "index2word_inp = pk.load(open(os.path.join(modelDir,'index2word_inp.pk'),'rb'))\n",
    "\n",
    "word2index_out = pk.load(open(os.path.join(modelDir,'word2index_out.pk'), 'rb'))\n",
    "index2word_out = pk.load(open(os.path.join(modelDir,'index2word_out.pk'),'rb'))\n",
    "\n",
    "X_input = pk.load(open(os.path.join(modelDir,'x_inp.pk'),'rb'))\n",
    "y_input = pk.load(open(os.path.join(modelDir,'y_inp.pk'),'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cortega/Documents/TF_chatbot/chatbot_env/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = load_model(os.path.join(modelDir, 'chpts/35_2.43.chpt'), custom_objects={'perplexity': perplexity})\n",
    "encoder_model = load_model(os.path.join(modelDir, 'encoder_model_128_32_155_264.h5'))\n",
    "decoder_model = load_model(os.path.join(modelDir, 'decoder_model_128_32_155_264.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.compile(optimizer=Nadam(), loss=perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.compile(optimizer=Nadam(), loss=perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, target_len, v=0, counter=None, n=None):\n",
    "    '''Generates answer from given sequence of word indexes'''\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, target_len))\n",
    "    # Populate the first token of target sequence with the start token.\n",
    "    target_seq[0, 0] = word2index_out['GO']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decode_sentence = []\n",
    "    prediction_index = 0\n",
    "    while not stop_condition:\n",
    "        ## Print sequence for debugging\n",
    "        #print(target_seq)\n",
    "        output_word_index, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        #print(output_word_index.shape)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_word_index = np.argmax(output_word_index[0, -1, :])\n",
    "        sampled_word = index2word_out[sampled_word_index]\n",
    "        decode_sentence.append(sampled_word)\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop token.\n",
    "        if (sampled_word == 'EOS' or len(decode_sentence) >= target_len):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq[0, prediction_index+1] = sampled_word_index\n",
    "            prediction_index += 1\n",
    "\n",
    "    ## Print sentece for debugging\n",
    "    # print(' '.join(decode_sentence))\n",
    "\n",
    "    # Update states\n",
    "    states_value = [h, c]\n",
    "    \n",
    "    if v == 1:\n",
    "        counter += 1\n",
    "        print('{} of {}'.format(counter, n), end='\\r')\n",
    "\n",
    "    return ' '.join(decode_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexseq2text(indexes_seq, index2word):\n",
    "    string_ = []\n",
    "    for val in indexes_seq:\n",
    "        string_.append(index2word[val])\n",
    "    \n",
    "    return ' '.join(string_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2indexseq(tokens, word2index):\n",
    "    indexseq = []\n",
    "    for word in tokens:\n",
    "        indexseq.append(word2index[word])\n",
    "    \n",
    "    return indexseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexseq = text2indexseq(['Buenos','dias','solicitar','un','certificado','de','egreso'], word2index_out)\n",
    "indexseq = np.array(indexseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexseq = sequence.pad_sequences([indexseq], maxlen=200, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 s, sys: 17.5 s, total: 59.3 s\n",
      "Wall time: 16.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'listado listado listado listado puedes puedes puedes pedido puede puede puede puede puede puede puede puede puede puede puede puede puede puede puede puede puede puede puede puede hasta hasta hasta menos menos menos julio julio julio disposicion Requisitos vez ese ese les perteneces les correcto correcto 08 08 podran podran Luego Luego Luego Luego Luego Luego su su su su su blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco blanco'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "decode_sequence(input_seq=indexseq,\n",
    "                target_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['input_string']  = [indexseq2text(X_input[i], index2word_inp) for i in range(X_input.shape[0])]\n",
    "result_df['real_string'] = [indexseq2text(y_input[i], index2word_out) for i in range(y_input.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df['predictions_string'] = [decode_sequence(X_input[i:i+1], y_input.shape[1], 1, i, y_input.shape[0]) for i in range(X_input.shape[0]-1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sample = np.random.randint(0, y_input.shape[0]-1, size=10)\n",
    "X_sample, y_sample = X_input[sample, :], y_input[sample, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_samples.txt','wb') as f:\n",
    "    sep = '-'*80\n",
    "    for i in range(X_input.shape[0]):\n",
    "        input_string = indexseq2text(X_input[i], index2word_inp)\n",
    "        print(input_string)\n",
    "        print(sep)\n",
    "        real_string = indexseq2text(y_input[i], index2word_out)\n",
    "        print(real_string)\n",
    "        if i < X_input.shape[0]-1:\n",
    "            predicted_string = decode_sequence(X_input[i:i+1], y_input.shape[1])\n",
    "        print(predicted_string)\n",
    "        \n",
    "            \n",
    "        \n",
    "        f.write()\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df['input_string']  = [indexseq2text(X_input[i], index2word_inp) for i in range(X_input.shape[0])]\n",
    "result_df['real_string'] = [indexseq2text(y_input[i], index2word_out) for i in range(y_input.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df['predictions_string'] = [decode_sequence(X_input[i:i+1], y_input.shape[1], 1, i, y_input.shape[0]) for i in range(X_input.shape[0]-1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sep = '-'*80\n",
    "for i in range(X_sample.shape[0]):\n",
    "    input_string = indexseq2text(X_sample[i], index2word_inp)\n",
    "    print(input_string)\n",
    "    print(sep)\n",
    "    real_string = indexseq2text(y_sample[i], index2word_out)\n",
    "    print(real_string)\n",
    "    if i < X_input.shape[0]-1:\n",
    "        predicted_string = decode_sequence(X_sample[i:i+1], y_sample.shape[1])\n",
    "    print(X_sample[i:i+1])\n",
    "    print(predicted_string)\n",
    "    print('*'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decode_sequence(np.array([range(200)]), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
